train:
  batch_size: 4
  num_epochs: 100
  n_splits: 5
  threshold: 0.5
   
  metric: 
    name: "dice_coef"
  # accuracy / f1 / precision / recall / mse / dice_coef
  
  criterion: 
    name: "BCEWithLogitsLoss"
  # CrossEntropyLoss / BCEWithLogitsLoss

  optimizer:
    name: "Adam"
    # Adam / SGD
    config:
      weight_decay: 1.e-6
      # momentum: 0.9
      lr: 1.e-4

  lr_scheduler:
    name: "ReduceLROnPlateau"
    monitor: "metric"
    config:
      factor: 0.1
      patience: 20
      min_lr: 1.e-6
      verbose: True

  early_stopping:
    patience: 3
    min_delta: 0.001
    evidence: 'loss'
    monitor: 'metric'

model:
  name: "myUnet"
  # fcn_50 /
  config:
    pretrained: True
  