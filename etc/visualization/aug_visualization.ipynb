{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "\n",
    "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n",
    "IND2CLASS = {v: k for k, v in CLASS2IND.items()}\n",
    "\n",
    "\n",
    "PALETTE = [\n",
    "    (220, 20, 60), (119, 11, 32), (0, 0, 142), (0, 0, 230), (106, 0, 228),\n",
    "    (0, 60, 100), (0, 80, 100), (0, 0, 70), (0, 0, 192), (250, 170, 30),\n",
    "    (100, 170, 30), (220, 220, 0), (175, 116, 175), (250, 0, 30), (165, 42, 42),\n",
    "    (255, 77, 255), (0, 226, 252), (182, 182, 255), (0, 82, 0), (120, 166, 157),\n",
    "    (110, 76, 0), (174, 57, 255), (199, 100, 0), (72, 0, 118), (255, 179, 240),\n",
    "    (0, 125, 92), (209, 0, 151), (188, 208, 182), (0, 220, 176),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강된 이미지 및 라벨 디렉토리 설정\n",
    "AUGMENTED_IMAGE_ROOT = \"/data/ephemeral/home/heejin/level2-cv-semanticsegmentation-cv-18-lv3/data/train/DCM_augmented/ID002\"\n",
    "AUGMENTED_LABEL_ROOT = \"/data/ephemeral/home/heejin/level2-cv-semanticsegmentation-cv-18-lv3/data/train/outputs_json_augmented/ID002\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2rgb(label: np.ndarray, height: int, width: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "     클래스 별 마스크를 색상 팔레트에 따라 RGB 이미지로 변환해주는 function\n",
    "    \"\"\"\n",
    "    image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for i, class_mask in enumerate(label):\n",
    "        color = PALETTE[i % len(PALETTE)]\n",
    "        image[class_mask == 1] = color\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths(directory: str):\n",
    "    image_paths = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths[f] = os.path.join(root, f)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_augmented_segmentation_pair(image_name: str):\n",
    "\n",
    "    \"\"\"\n",
    "        증강된 이미지와 해당 이미지의 polygon 시각화 \n",
    "    \"\"\"\n",
    "    image_path = os.path.join(AUGMENTED_IMAGE_ROOT, image_name)\n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    label_name = f\"{base_name}.json\"\n",
    "    label_path = os.path.join(AUGMENTED_LABEL_ROOT, label_name)\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Augmented image not found: {image_path}\")\n",
    "        return\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"Augmented label not found: {label_path}\")\n",
    "        return\n",
    "    \n",
    "    # 이미지 로드\n",
    "    try:\n",
    "        image = np.array(Image.open(image_path).convert('RGB'))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load image {image_path}: {e}\")\n",
    "        return\n",
    "    height, width = image.shape[:2]\n",
    "    mask = np.zeros((len(CLASSES), height, width), dtype=np.uint8)\n",
    "    \n",
    "    # 라벨 로드\n",
    "    try:\n",
    "        with open(label_path, \"r\") as f:\n",
    "            annotations = json.load(f)[\"annotations\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load label {label_path}: {e}\")\n",
    "        return\n",
    "    \n",
    "    for ann in annotations:\n",
    "        class_name = ann.get(\"label\")\n",
    "        points = ann.get(\"points\")\n",
    "        if class_name not in CLASS2IND:\n",
    "            print(f\"Unknown class: {class_name}\")\n",
    "            continue\n",
    "        class_idx = CLASS2IND[class_name]\n",
    "        if not isinstance(points, list):\n",
    "            print(f\"Invalid points format for class {class_name} in {label_name}\")\n",
    "            continue\n",
    "        try:\n",
    "            polygon = np.array(points, dtype=np.int32)\n",
    "            if polygon.ndim != 2 or polygon.shape[1] != 2:\n",
    "                print(f\"Invalid polygon shape for class {class_name} in {label_name}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing points for class {class_name} in {label_name}: {e}\")\n",
    "            continue\n",
    "        cv2.fillPoly(mask[class_idx], [polygon], 1)\n",
    "    \n",
    "    # 마스크 색칠\n",
    "    color_mask = label2rgb(mask, height, width)\n",
    "    \n",
    "    # 이미지와 마스크 블렌딩\n",
    "    try:\n",
    "        blended = cv2.addWeighted(image, 0.5, color_mask, 0.5, 0)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to blend image and mask for {image_name}: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Augmented Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(blended)\n",
    "    axes[1].set_title(\"Augmented Segmentation\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(num_samples: int = 5):\n",
    "    augmented_files = [f for f in os.listdir(AUGMENTED_IMAGE_ROOT) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    selected_files = augmented_files[:num_samples]\n",
    "    \n",
    "    print(f\"Displaying {len(selected_files)} augmented segmentation pairs.\")\n",
    "    for image_name in selected_files:\n",
    "        display_augmented_segmentation_pair(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    visualization()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
